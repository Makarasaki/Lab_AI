{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRINGS_LIST_LEN = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = ['a', 'b', 'c', 'd']\n",
    "pattern = 'abcda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaaaaaaaaabcda 15\n"
     ]
    }
   ],
   "source": [
    "def insert_pattern(string: str):\n",
    "    index = random.randint(0, 10)\n",
    "    string = string[:index] + pattern + string[index + len(pattern):]\n",
    "    return string\n",
    "out = insert_pattern('aaaaaaaaaaaaaaa')\n",
    "print(out, len(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = []\n",
    "labels = []\n",
    "for i in range(STRINGS_LIST_LEN):\n",
    "    strings.append(''.join(random.choices(alphabet, k=15)))\n",
    "    if i % 2 == 0 and not re.search(pattern, strings[i]):\n",
    "        strings[i] = insert_pattern(strings[i])\n",
    "    if i % 2 == 1 and re.search(pattern, strings[i]):\n",
    "        strings[i] = re.sub(pattern, ''.join(random.choices(alphabet, k=5)), strings[i], 1)\n",
    "        while re.search(pattern, strings[i]):\n",
    "            strings[i] = re.sub(pattern, ''.join(random.choices(alphabet, k=5)), strings[i], 1)\n",
    "    labels.append((i+1)%2)\n",
    "    # if i % 2 == 0: labels.append(1)\n",
    "    # else: labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ddbaabaacdbbcca 0\n",
      "bddcdabcbcbcacb 0\n",
      "abaabcdaabbdbcb 1\n",
      "dadccaabdcbdcca 0\n",
      "bccbadcddacdbdb 0\n",
      "dbcaadabcdacdcb 1\n",
      "bcbbabcdabbbadb 1\n",
      "dcbcadbdaaaacbb 0\n",
      "badabbaaaabcdad 1\n",
      "cbbacddcaabcdab 1\n"
     ]
    }
   ],
   "source": [
    "temp = list(zip(strings, labels))\n",
    "random.shuffle(temp)\n",
    "strings, labels = zip(*temp)\n",
    "strings, labels = list(strings), list(labels)\n",
    "\n",
    "for i in range(10):   \n",
    "    print(strings[i], labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_strings = [tf.keras.utils.to_categorical(np.array([alphabet.index(letter) for letter in string]), num_classes=len(alphabet)) for string in strings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "train_strings = np.array(hot_strings[:8000])\n",
    "train_labels = np.array(labels[:8000])\n",
    "\n",
    "test_strings = np.array(hot_strings[8000:])\n",
    "test_labels = np.array(labels[8000:])\n",
    "print(train_strings[0])\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_3 (Conv1D)           (None, 11, 1)             21        \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 11)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33\n",
      "Trainable params: 33\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = tf.keras.models.Sequential()\n",
    "model_1.add(tf.keras.layers.Conv1D(filters=1, kernel_size=5, activation='relu', input_shape=(15, 4)))\n",
    "model_1.add(tf.keras.layers.Flatten())\n",
    "# model_1.add(tf.keras.layers.Dense(10, activation='sigmoid'))\n",
    "model_1.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "model_1.summary()\n",
    "model_1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6945 - accuracy: 0.5368 - val_loss: 0.6719 - val_accuracy: 0.5650\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.6616 - accuracy: 0.6109 - val_loss: 0.6462 - val_accuracy: 0.6500\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.6406 - accuracy: 0.6635 - val_loss: 0.6266 - val_accuracy: 0.6795\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.6207 - accuracy: 0.6879 - val_loss: 0.6070 - val_accuracy: 0.6890\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.6016 - accuracy: 0.6977 - val_loss: 0.5895 - val_accuracy: 0.7090\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5859 - accuracy: 0.7081 - val_loss: 0.5759 - val_accuracy: 0.7180\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5733 - accuracy: 0.7175 - val_loss: 0.5648 - val_accuracy: 0.7215\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5625 - accuracy: 0.7215 - val_loss: 0.5558 - val_accuracy: 0.7250\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5537 - accuracy: 0.7284 - val_loss: 0.5479 - val_accuracy: 0.7265\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5463 - accuracy: 0.7314 - val_loss: 0.5414 - val_accuracy: 0.7275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2477782a7f0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train the model_1\n",
    "model_1.fit(train_strings, train_labels, epochs=10, batch_size=32, validation_data=(test_strings, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.2549068   0.25266325  0.2580355  -0.33550078]\n",
      " [ 0.10440952  0.07230814 -0.19184707  0.07905141]\n",
      " [-0.89782286  0.08461267 -0.0964635   0.05429755]\n",
      " [-0.56495476  0.0907548   0.06626719  0.73877513]\n",
      " [-0.8935974   0.2716938   0.5259349  -0.43592164]]\n"
     ]
    }
   ],
   "source": [
    "filter = model_1.layers[0].get_weights()[0][:, :, 0]\n",
    "print(filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5414 - accuracy: 0.7275\n",
      "loss: 0.5413827896118164, accuracy: 0.7275000214576721\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_1.evaluate(test_strings, test_labels)\n",
    "print(f'loss: {loss}, accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 70ms/step\n",
      "[[0.7540543 ]\n",
      " [0.02042863]\n",
      " [0.08621658]\n",
      " [0.72168124]\n",
      " [0.52918416]\n",
      " [0.362359  ]\n",
      " [0.53752214]]\n"
     ]
    }
   ],
   "source": [
    "your_str = ['aaaaaaaaaaaaaaa', # 0\n",
    "            'bbbbbbbbbbbbbbb', # 0\n",
    "            'ccccccccccccccc', # 0\n",
    "            'ddddddddddddddd', # 0\n",
    "            'abcdadbcabdaddc', # 1\n",
    "            'acbacbdacbdbcda', # 0\n",
    "            'adcbadcbabcdabc'] # 1\n",
    "your_hot_str = np.array([tf.keras.utils.to_categorical(np.array([alphabet.index(letter) for letter in string[:15]]), num_classes=len(alphabet)) for string in your_str])\n",
    "# print(your_hot_str[0], len(your_hot_str))\n",
    "\n",
    "result = model_1.predict([your_hot_str])\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model with one filter: accuracy varies between 0.7 and 0.94\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid activation function got much better results than activation relu function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```[[-0.9766118   0.8987984  -1.0841043  -1.103324  ]\n",
    " [-1.1577314  -1.0720665   0.8588849  -1.1252344 ]\n",
    " [-1.4096966  -1.2763376  -1.2028228   0.6865602 ]\n",
    " [ 0.5466621  -1.4944448  -1.5552505  -1.4274256 ]\n",
    " [-0.36988205 -0.25175053 -0.46649975 -0.4346084 ]]\n",
    "```\n",
    " loss: 0.21468232572078705, accuracy: 0.9419999718666077"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_20 (Conv1D)          (None, 11, 2)             42        \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 11, 2)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_21 (Conv1D)          (None, 7, 2)              22        \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 14)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 10)                150       \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 225\n",
      "Trainable params: 225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = tf.keras.models.Sequential()\n",
    "model_2.add(tf.keras.layers.Conv1D(filters=2, kernel_size=5, activation='relu', input_shape=(15, 4)))\n",
    "model_2.add(tf.keras.layers.MaxPool1D(pool_size=2, strides=1, padding='same'))\n",
    "model_2.add(tf.keras.layers.Conv1D(filters=2, kernel_size=5, activation='relu', input_shape=(15, 4)))\n",
    "# model_2.add(tf.keras.layers.MaxPool1D(pool_size=2, strides=1, padding='same'))\n",
    "model_2.add(tf.keras.layers.Flatten())\n",
    "model_2.add(tf.keras.layers.Dense(10, activation='sigmoid'))\n",
    "model_2.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "model_2.summary()\n",
    "model_2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 2s 4ms/step - loss: 0.7214 - accuracy: 0.5014 - val_loss: 0.6936 - val_accuracy: 0.4945\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6767 - accuracy: 0.5465 - val_loss: 0.6337 - val_accuracy: 0.7025\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5829 - accuracy: 0.7387 - val_loss: 0.5547 - val_accuracy: 0.7480\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5224 - accuracy: 0.7676 - val_loss: 0.5015 - val_accuracy: 0.7785\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4685 - accuracy: 0.7961 - val_loss: 0.4529 - val_accuracy: 0.8090\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4190 - accuracy: 0.8263 - val_loss: 0.4029 - val_accuracy: 0.8395\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3687 - accuracy: 0.8614 - val_loss: 0.3542 - val_accuracy: 0.8710\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3202 - accuracy: 0.8934 - val_loss: 0.3078 - val_accuracy: 0.8995\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2802 - accuracy: 0.9099 - val_loss: 0.2746 - val_accuracy: 0.9115\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2497 - accuracy: 0.9211 - val_loss: 0.2502 - val_accuracy: 0.9180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24781563a30>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model_2 \n",
    "model_2.fit(train_strings, train_labels, epochs=10, batch_size=32, validation_data=(test_strings, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter1 = model_2.layers[0].get_weights()[0][:, :, 0]\n",
    "# filter2 = model_2.layers[0].get_weights()[1][:, :, 0]\n",
    "# print(filter1, filter2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.9180\n",
      "loss: 0.25019821524620056, accuracy: 0.9179999828338623\n"
     ]
    }
   ],
   "source": [
    "loss_2, accuracy_2 = model_2.evaluate(test_strings, test_labels)\n",
    "print(f'loss: {loss_2}, accuracy: {accuracy_2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step\n",
      "[[0.7497108 ]\n",
      " [0.66065943]\n",
      " [0.7497108 ]\n",
      " [0.05385881]\n",
      " [0.3298482 ]\n",
      " [0.13850188]\n",
      " [0.8188818 ]]\n"
     ]
    }
   ],
   "source": [
    "your_str = ['aaaaaaaaaaaaaaa', # 0\n",
    "            'bbbbbbbbbbbbbbb', # 0\n",
    "            'ccccccccccccccc', # 0\n",
    "            'ddddddddddddddd', # 0\n",
    "            'abcdadbcabdaddc', # 1\n",
    "            'acbacbdacbdbcda', # 0\n",
    "            'adcbadcbabcdabc'] # 1\n",
    "your_hot_str = np.array([tf.keras.utils.to_categorical(np.array([alphabet.index(letter) for letter in string[:15]]), num_classes=len(alphabet)) for string in your_str])\n",
    "# print(your_hot_str[0], len(your_hot_str))\n",
    "\n",
    "result = model_2.predict([your_hot_str])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.autograd import Variable\n",
    "# class Model_1_PT(torch.nn.Module):\n",
    "#     def __init__(self) -> None:\n",
    "#         super().__init__()\n",
    "#         self.model = torch.nn.Sequential(\n",
    "#             torch.nn.Conv1d(15, 11, 4),\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.Flatten(),\n",
    "#             torch.nn.Linear(11, 1)\n",
    "#         )\n",
    "#         self.double()\n",
    "    \n",
    "#     def forward(self, input):\n",
    "#         return self.model(input)\n",
    "    \n",
    "#     def train(self, train_strings, train_labels):\n",
    "#         loss_function = torch.nn.BCELoss()\n",
    "#         optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "#         # accuracy=tf.keras.metrics.BinaryAccuracy()\n",
    "#         for epoch in range(100):\n",
    "#             # print('wpadlo1')\n",
    "#             output = self.forward(train_strings)\n",
    "#             # print(output, train_labels)\n",
    "#             loss = loss_function(output, train_labels)\n",
    "#             # print('wpadlo')\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             # accuracy(output, train_labels)\n",
    "    \n",
    "# model_1_pt = Model_1_PT().float()\n",
    "\n",
    "# model_1_pt.forward(torch.tensor(np.array(train_strings)))\n",
    "\n",
    "# print(model_1_pt)\n",
    "# # model_1_pt.forward(torch.tensor(train_strings))\n",
    "# # train_labels_r = []\n",
    "# # for index, value in enumerate(train_labels):\n",
    "# #     # print(index)\n",
    "# #     train_labels_r.append([float(value)])\n",
    "# # print('torch.empty(3).random_(2)', torch.empty(3).random_(2))\n",
    "# train_labels_r = np.array(train_labels)\n",
    "# train_labels_r=np.reshape(train_labels_r, (8000,1))\n",
    "# train_labels_r = Variable(torch.from_numpy(train_labels_r)).float()\n",
    "# train_strings_V2 = Variable(torch.from_numpy(train_strings)).float()\n",
    "# train_strings_V1 = torch.tensor(np.array(train_strings)).float()\n",
    "# model_1_pt.train(train_strings_V1, train_labels_r)\n",
    "\n",
    "# output = model_1_pt.forward(torch.tensor(np.array(test_strings)))\n",
    "# print(output)\n",
    "# print(test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ef62e107a064dbfd5e93c8f3e183a806b4e7ca7d8553a94a3d8653eafa81f18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
